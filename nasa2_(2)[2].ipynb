{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NASA Space Apps 2025: Hunting Exoplanets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the TESS Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "UvWKv0bw7_pl",
        "outputId": "363d7a07-496c-479c-fa9b-e7f75442984f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toi</th>\n",
              "      <th>tid</th>\n",
              "      <th>tfopwg_disp</th>\n",
              "      <th>rastr</th>\n",
              "      <th>ra</th>\n",
              "      <th>decstr</th>\n",
              "      <th>dec</th>\n",
              "      <th>st_pmra</th>\n",
              "      <th>st_pmraerr1</th>\n",
              "      <th>st_pmraerr2</th>\n",
              "      <th>st_pmralim</th>\n",
              "      <th>st_pmdec</th>\n",
              "      <th>st_pmdecerr1</th>\n",
              "      <th>st_pmdecerr2</th>\n",
              "      <th>st_pmdeclim</th>\n",
              "      <th>pl_tranmid</th>\n",
              "      <th>pl_tranmiderr1</th>\n",
              "      <th>pl_tranmiderr2</th>\n",
              "      <th>pl_tranmidlim</th>\n",
              "      <th>pl_orbper</th>\n",
              "      <th>pl_orbpererr1</th>\n",
              "      <th>pl_orbpererr2</th>\n",
              "      <th>pl_orbperlim</th>\n",
              "      <th>pl_trandurh</th>\n",
              "      <th>pl_trandurherr1</th>\n",
              "      <th>pl_trandurherr2</th>\n",
              "      <th>pl_trandurhlim</th>\n",
              "      <th>pl_trandep</th>\n",
              "      <th>pl_trandeperr1</th>\n",
              "      <th>pl_trandeperr2</th>\n",
              "      <th>pl_trandeplim</th>\n",
              "      <th>pl_rade</th>\n",
              "      <th>pl_radeerr1</th>\n",
              "      <th>pl_radeerr2</th>\n",
              "      <th>pl_radelim</th>\n",
              "      <th>pl_insol</th>\n",
              "      <th>pl_insolerr1</th>\n",
              "      <th>pl_insolerr2</th>\n",
              "      <th>pl_insollim</th>\n",
              "      <th>pl_eqt</th>\n",
              "      <th>pl_eqterr1</th>\n",
              "      <th>pl_eqterr2</th>\n",
              "      <th>pl_eqtlim</th>\n",
              "      <th>st_tmag</th>\n",
              "      <th>st_tmagerr1</th>\n",
              "      <th>st_tmagerr2</th>\n",
              "      <th>st_tmaglim</th>\n",
              "      <th>st_dist</th>\n",
              "      <th>st_disterr1</th>\n",
              "      <th>st_disterr2</th>\n",
              "      <th>st_distlim</th>\n",
              "      <th>st_teff</th>\n",
              "      <th>st_tefferr1</th>\n",
              "      <th>st_tefferr2</th>\n",
              "      <th>st_tefflim</th>\n",
              "      <th>st_logg</th>\n",
              "      <th>st_loggerr1</th>\n",
              "      <th>st_loggerr2</th>\n",
              "      <th>st_logglim</th>\n",
              "      <th>st_rad</th>\n",
              "      <th>st_raderr1</th>\n",
              "      <th>st_raderr2</th>\n",
              "      <th>st_radlim</th>\n",
              "      <th>toi_created</th>\n",
              "      <th>rowupdate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.01</td>\n",
              "      <td>50365310</td>\n",
              "      <td>FP</td>\n",
              "      <td>07h29m25.85s</td>\n",
              "      <td>112.357708</td>\n",
              "      <td>-12d41m45.46s</td>\n",
              "      <td>-12.695960</td>\n",
              "      <td>-5.964</td>\n",
              "      <td>0.085</td>\n",
              "      <td>-0.085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.076</td>\n",
              "      <td>0.072</td>\n",
              "      <td>-0.072</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.459230e+06</td>\n",
              "      <td>0.001657</td>\n",
              "      <td>-0.001657</td>\n",
              "      <td>0</td>\n",
              "      <td>2.171348</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>-0.000264</td>\n",
              "      <td>0</td>\n",
              "      <td>2.01722</td>\n",
              "      <td>0.319588</td>\n",
              "      <td>-0.319588</td>\n",
              "      <td>0</td>\n",
              "      <td>656.886099</td>\n",
              "      <td>37.778210</td>\n",
              "      <td>-37.778210</td>\n",
              "      <td>0</td>\n",
              "      <td>5.818163</td>\n",
              "      <td>1.910546</td>\n",
              "      <td>-1.910546</td>\n",
              "      <td>0</td>\n",
              "      <td>22601.948581</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3127.204052</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.604000</td>\n",
              "      <td>0.013</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>0</td>\n",
              "      <td>485.735</td>\n",
              "      <td>11.9515</td>\n",
              "      <td>-11.9515</td>\n",
              "      <td>0</td>\n",
              "      <td>10249.0</td>\n",
              "      <td>264.7</td>\n",
              "      <td>-264.7</td>\n",
              "      <td>0</td>\n",
              "      <td>4.19</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0</td>\n",
              "      <td>2.16986</td>\n",
              "      <td>0.072573</td>\n",
              "      <td>-0.072573</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-07-24 15:58:33</td>\n",
              "      <td>2024-09-09 10:08:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001.01</td>\n",
              "      <td>88863718</td>\n",
              "      <td>PC</td>\n",
              "      <td>08h10m19.31s</td>\n",
              "      <td>122.580465</td>\n",
              "      <td>-05d30m49.87s</td>\n",
              "      <td>-5.513852</td>\n",
              "      <td>-4.956</td>\n",
              "      <td>0.102</td>\n",
              "      <td>-0.102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-15.555</td>\n",
              "      <td>0.072</td>\n",
              "      <td>-0.072</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.459988e+06</td>\n",
              "      <td>0.001916</td>\n",
              "      <td>-0.001916</td>\n",
              "      <td>0</td>\n",
              "      <td>1.931646</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-0.000005</td>\n",
              "      <td>0</td>\n",
              "      <td>3.16600</td>\n",
              "      <td>0.647000</td>\n",
              "      <td>-0.647000</td>\n",
              "      <td>0</td>\n",
              "      <td>1286.000000</td>\n",
              "      <td>1186.490000</td>\n",
              "      <td>-1186.490000</td>\n",
              "      <td>0</td>\n",
              "      <td>11.215400</td>\n",
              "      <td>2.624200</td>\n",
              "      <td>-2.624200</td>\n",
              "      <td>0</td>\n",
              "      <td>44464.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4045.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.423440</td>\n",
              "      <td>0.006</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0</td>\n",
              "      <td>295.862</td>\n",
              "      <td>5.9100</td>\n",
              "      <td>-5.9100</td>\n",
              "      <td>0</td>\n",
              "      <td>7070.0</td>\n",
              "      <td>126.4</td>\n",
              "      <td>-126.4</td>\n",
              "      <td>0</td>\n",
              "      <td>4.03</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>0</td>\n",
              "      <td>2.01000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>-0.090000</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-07-24 15:58:33</td>\n",
              "      <td>2023-04-03 14:31:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1002.01</td>\n",
              "      <td>124709665</td>\n",
              "      <td>FP</td>\n",
              "      <td>06h58m54.47s</td>\n",
              "      <td>104.726966</td>\n",
              "      <td>-10d34m49.64s</td>\n",
              "      <td>-10.580455</td>\n",
              "      <td>-1.462</td>\n",
              "      <td>0.206</td>\n",
              "      <td>-0.206</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.249</td>\n",
              "      <td>0.206</td>\n",
              "      <td>-0.206</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.459225e+06</td>\n",
              "      <td>0.000625</td>\n",
              "      <td>-0.000625</td>\n",
              "      <td>0</td>\n",
              "      <td>1.867557</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>-0.000003</td>\n",
              "      <td>0</td>\n",
              "      <td>1.40800</td>\n",
              "      <td>0.184000</td>\n",
              "      <td>-0.184000</td>\n",
              "      <td>0</td>\n",
              "      <td>1500.000000</td>\n",
              "      <td>1.758400</td>\n",
              "      <td>-1.758400</td>\n",
              "      <td>0</td>\n",
              "      <td>23.752900</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2860.610000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2037.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.299501</td>\n",
              "      <td>0.058</td>\n",
              "      <td>-0.058</td>\n",
              "      <td>0</td>\n",
              "      <td>943.109</td>\n",
              "      <td>106.3330</td>\n",
              "      <td>-106.3330</td>\n",
              "      <td>0</td>\n",
              "      <td>8924.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>-124.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5.73000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-07-24 15:58:33</td>\n",
              "      <td>2022-07-11 16:02:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1003.01</td>\n",
              "      <td>106997505</td>\n",
              "      <td>FP</td>\n",
              "      <td>07h22m14.39s</td>\n",
              "      <td>110.559945</td>\n",
              "      <td>-25d12m25.26s</td>\n",
              "      <td>-25.207017</td>\n",
              "      <td>-0.939</td>\n",
              "      <td>0.041</td>\n",
              "      <td>-0.041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.640</td>\n",
              "      <td>0.055</td>\n",
              "      <td>-0.055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.458493e+06</td>\n",
              "      <td>0.005350</td>\n",
              "      <td>-0.005350</td>\n",
              "      <td>0</td>\n",
              "      <td>2.743230</td>\n",
              "      <td>0.001080</td>\n",
              "      <td>-0.001080</td>\n",
              "      <td>0</td>\n",
              "      <td>3.16700</td>\n",
              "      <td>0.642000</td>\n",
              "      <td>-0.642000</td>\n",
              "      <td>0</td>\n",
              "      <td>383.410000</td>\n",
              "      <td>0.781988</td>\n",
              "      <td>-0.781988</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1177.360000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1631.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.300300</td>\n",
              "      <td>0.037</td>\n",
              "      <td>-0.037</td>\n",
              "      <td>0</td>\n",
              "      <td>7728.170</td>\n",
              "      <td>1899.5700</td>\n",
              "      <td>-1899.5700</td>\n",
              "      <td>0</td>\n",
              "      <td>5388.5</td>\n",
              "      <td>567.0</td>\n",
              "      <td>-567.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.15</td>\n",
              "      <td>1.64</td>\n",
              "      <td>-1.64</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-07-24 15:58:33</td>\n",
              "      <td>2022-02-23 10:10:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1004.01</td>\n",
              "      <td>238597883</td>\n",
              "      <td>FP</td>\n",
              "      <td>08h08m42.77s</td>\n",
              "      <td>122.178195</td>\n",
              "      <td>-48d48m10.12s</td>\n",
              "      <td>-48.802811</td>\n",
              "      <td>-4.496</td>\n",
              "      <td>0.069</td>\n",
              "      <td>-0.069</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.347</td>\n",
              "      <td>0.062</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.459987e+06</td>\n",
              "      <td>0.003748</td>\n",
              "      <td>-0.003748</td>\n",
              "      <td>0</td>\n",
              "      <td>3.573014</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>-0.000013</td>\n",
              "      <td>0</td>\n",
              "      <td>3.37000</td>\n",
              "      <td>1.029000</td>\n",
              "      <td>-1.029000</td>\n",
              "      <td>0</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>1306.550000</td>\n",
              "      <td>-1306.550000</td>\n",
              "      <td>0</td>\n",
              "      <td>11.311300</td>\n",
              "      <td>3.247140</td>\n",
              "      <td>-3.247140</td>\n",
              "      <td>0</td>\n",
              "      <td>54679.300000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4260.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.135500</td>\n",
              "      <td>0.006</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0</td>\n",
              "      <td>356.437</td>\n",
              "      <td>4.6175</td>\n",
              "      <td>-4.6175</td>\n",
              "      <td>0</td>\n",
              "      <td>9219.0</td>\n",
              "      <td>171.1</td>\n",
              "      <td>-171.1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0</td>\n",
              "      <td>2.15000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>-0.060000</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-07-24 15:58:33</td>\n",
              "      <td>2024-09-09 10:08:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       toi        tid tfopwg_disp         rastr          ra         decstr  \\\n",
              "0  1000.01   50365310          FP  07h29m25.85s  112.357708  -12d41m45.46s   \n",
              "1  1001.01   88863718          PC  08h10m19.31s  122.580465  -05d30m49.87s   \n",
              "2  1002.01  124709665          FP  06h58m54.47s  104.726966  -10d34m49.64s   \n",
              "3  1003.01  106997505          FP  07h22m14.39s  110.559945  -25d12m25.26s   \n",
              "4  1004.01  238597883          FP  08h08m42.77s  122.178195  -48d48m10.12s   \n",
              "\n",
              "         dec  st_pmra  st_pmraerr1  st_pmraerr2  st_pmralim  st_pmdec  \\\n",
              "0 -12.695960   -5.964        0.085       -0.085         0.0    -0.076   \n",
              "1  -5.513852   -4.956        0.102       -0.102         0.0   -15.555   \n",
              "2 -10.580455   -1.462        0.206       -0.206         0.0    -2.249   \n",
              "3 -25.207017   -0.939        0.041       -0.041         0.0     1.640   \n",
              "4 -48.802811   -4.496        0.069       -0.069         0.0     9.347   \n",
              "\n",
              "   st_pmdecerr1  st_pmdecerr2  st_pmdeclim    pl_tranmid  pl_tranmiderr1  \\\n",
              "0         0.072        -0.072          0.0  2.459230e+06        0.001657   \n",
              "1         0.072        -0.072          0.0  2.459988e+06        0.001916   \n",
              "2         0.206        -0.206          0.0  2.459225e+06        0.000625   \n",
              "3         0.055        -0.055          0.0  2.458493e+06        0.005350   \n",
              "4         0.062        -0.062          0.0  2.459987e+06        0.003748   \n",
              "\n",
              "   pl_tranmiderr2  pl_tranmidlim  pl_orbper  pl_orbpererr1  pl_orbpererr2  \\\n",
              "0       -0.001657              0   2.171348       0.000264      -0.000264   \n",
              "1       -0.001916              0   1.931646       0.000005      -0.000005   \n",
              "2       -0.000625              0   1.867557       0.000003      -0.000003   \n",
              "3       -0.005350              0   2.743230       0.001080      -0.001080   \n",
              "4       -0.003748              0   3.573014       0.000013      -0.000013   \n",
              "\n",
              "   pl_orbperlim  pl_trandurh  pl_trandurherr1  pl_trandurherr2  \\\n",
              "0             0      2.01722         0.319588        -0.319588   \n",
              "1             0      3.16600         0.647000        -0.647000   \n",
              "2             0      1.40800         0.184000        -0.184000   \n",
              "3             0      3.16700         0.642000        -0.642000   \n",
              "4             0      3.37000         1.029000        -1.029000   \n",
              "\n",
              "   pl_trandurhlim   pl_trandep  pl_trandeperr1  pl_trandeperr2  pl_trandeplim  \\\n",
              "0               0   656.886099       37.778210      -37.778210              0   \n",
              "1               0  1286.000000     1186.490000    -1186.490000              0   \n",
              "2               0  1500.000000        1.758400       -1.758400              0   \n",
              "3               0   383.410000        0.781988       -0.781988              0   \n",
              "4               0   755.000000     1306.550000    -1306.550000              0   \n",
              "\n",
              "     pl_rade  pl_radeerr1  pl_radeerr2  pl_radelim      pl_insol  \\\n",
              "0   5.818163     1.910546    -1.910546           0  22601.948581   \n",
              "1  11.215400     2.624200    -2.624200           0  44464.500000   \n",
              "2  23.752900          NaN          NaN           0   2860.610000   \n",
              "3        NaN          NaN          NaN           0   1177.360000   \n",
              "4  11.311300     3.247140    -3.247140           0  54679.300000   \n",
              "\n",
              "   pl_insolerr1  pl_insolerr2  pl_insollim       pl_eqt  pl_eqterr1  \\\n",
              "0           NaN           NaN          NaN  3127.204052         NaN   \n",
              "1           NaN           NaN          NaN  4045.000000         NaN   \n",
              "2           NaN           NaN          NaN  2037.000000         NaN   \n",
              "3           NaN           NaN          NaN  1631.000000         NaN   \n",
              "4           NaN           NaN          NaN  4260.000000         NaN   \n",
              "\n",
              "   pl_eqterr2  pl_eqtlim   st_tmag  st_tmagerr1  st_tmagerr2  st_tmaglim  \\\n",
              "0         NaN        NaN  9.604000        0.013       -0.013           0   \n",
              "1         NaN        NaN  9.423440        0.006       -0.006           0   \n",
              "2         NaN        NaN  9.299501        0.058       -0.058           0   \n",
              "3         NaN        NaN  9.300300        0.037       -0.037           0   \n",
              "4         NaN        NaN  9.135500        0.006       -0.006           0   \n",
              "\n",
              "    st_dist  st_disterr1  st_disterr2  st_distlim  st_teff  st_tefferr1  \\\n",
              "0   485.735      11.9515     -11.9515           0  10249.0        264.7   \n",
              "1   295.862       5.9100      -5.9100           0   7070.0        126.4   \n",
              "2   943.109     106.3330    -106.3330           0   8924.0        124.0   \n",
              "3  7728.170    1899.5700   -1899.5700           0   5388.5        567.0   \n",
              "4   356.437       4.6175      -4.6175           0   9219.0        171.1   \n",
              "\n",
              "   st_tefferr2  st_tefflim  st_logg  st_loggerr1  st_loggerr2  st_logglim  \\\n",
              "0       -264.7           0     4.19         0.07        -0.07           0   \n",
              "1       -126.4           0     4.03         0.09        -0.09           0   \n",
              "2       -124.0           0      NaN          NaN          NaN           0   \n",
              "3       -567.0           0     4.15         1.64        -1.64           0   \n",
              "4       -171.1           0     4.14         0.07        -0.07           0   \n",
              "\n",
              "    st_rad  st_raderr1  st_raderr2  st_radlim          toi_created  \\\n",
              "0  2.16986    0.072573   -0.072573          0  2019-07-24 15:58:33   \n",
              "1  2.01000    0.090000   -0.090000          0  2019-07-24 15:58:33   \n",
              "2  5.73000         NaN         NaN          0  2019-07-24 15:58:33   \n",
              "3      NaN         NaN         NaN          0  2019-07-24 15:58:33   \n",
              "4  2.15000    0.060000   -0.060000          0  2019-07-24 15:58:33   \n",
              "\n",
              "             rowupdate  \n",
              "0  2024-09-09 10:08:01  \n",
              "1  2023-04-03 14:31:04  \n",
              "2  2022-07-11 16:02:02  \n",
              "3  2022-02-23 10:10:02  \n",
              "4  2024-09-09 10:08:01  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/mohammadsammour/Nasa-Challenge/main/Nasa_Dataset_1.csv\"\n",
        "main_data = pd.read_csv(url)\n",
        "pd.set_option('display.max_columns', None) # to show all columns\n",
        "pd.set_option('display.width', None) # each row will be shown in a line\n",
        "main_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfXTz5xFA5WQ",
        "outputId": "ce19cc7c-f8a0-459f-d6ab-f5c09ab35d6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7668, 65)\n",
            "64248\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7668 entries, 0 to 7667\n",
            "Data columns (total 65 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   toi              7668 non-null   float64\n",
            " 1   tid              7668 non-null   int64  \n",
            " 2   tfopwg_disp      7668 non-null   object \n",
            " 3   rastr            7668 non-null   object \n",
            " 4   ra               7668 non-null   float64\n",
            " 5   decstr           7668 non-null   object \n",
            " 6   dec              7668 non-null   float64\n",
            " 7   st_pmra          7534 non-null   float64\n",
            " 8   st_pmraerr1      7534 non-null   float64\n",
            " 9   st_pmraerr2      7534 non-null   float64\n",
            " 10  st_pmralim       7534 non-null   float64\n",
            " 11  st_pmdec         7534 non-null   float64\n",
            " 12  st_pmdecerr1     7534 non-null   float64\n",
            " 13  st_pmdecerr2     7534 non-null   float64\n",
            " 14  st_pmdeclim      7534 non-null   float64\n",
            " 15  pl_tranmid       7668 non-null   float64\n",
            " 16  pl_tranmiderr1   7657 non-null   float64\n",
            " 17  pl_tranmiderr2   7657 non-null   float64\n",
            " 18  pl_tranmidlim    7668 non-null   int64  \n",
            " 19  pl_orbper        7562 non-null   float64\n",
            " 20  pl_orbpererr1    7538 non-null   float64\n",
            " 21  pl_orbpererr2    7538 non-null   float64\n",
            " 22  pl_orbperlim     7668 non-null   int64  \n",
            " 23  pl_trandurh      7668 non-null   float64\n",
            " 24  pl_trandurherr1  7655 non-null   float64\n",
            " 25  pl_trandurherr2  7655 non-null   float64\n",
            " 26  pl_trandurhlim   7668 non-null   int64  \n",
            " 27  pl_trandep       7668 non-null   float64\n",
            " 28  pl_trandeperr1   7662 non-null   float64\n",
            " 29  pl_trandeperr2   7662 non-null   float64\n",
            " 30  pl_trandeplim    7668 non-null   int64  \n",
            " 31  pl_rade          7164 non-null   float64\n",
            " 32  pl_radeerr1      6047 non-null   float64\n",
            " 33  pl_radeerr2      6047 non-null   float64\n",
            " 34  pl_radelim       7668 non-null   int64  \n",
            " 35  pl_insol         7492 non-null   float64\n",
            " 36  pl_insolerr1     0 non-null      float64\n",
            " 37  pl_insolerr2     0 non-null      float64\n",
            " 38  pl_insollim      0 non-null      float64\n",
            " 39  pl_eqt           7357 non-null   float64\n",
            " 40  pl_eqterr1       0 non-null      float64\n",
            " 41  pl_eqterr2       0 non-null      float64\n",
            " 42  pl_eqtlim        0 non-null      float64\n",
            " 43  st_tmag          7668 non-null   float64\n",
            " 44  st_tmagerr1      7668 non-null   float64\n",
            " 45  st_tmagerr2      7668 non-null   float64\n",
            " 46  st_tmaglim       7668 non-null   int64  \n",
            " 47  st_dist          7453 non-null   float64\n",
            " 48  st_disterr1      6962 non-null   float64\n",
            " 49  st_disterr2      6962 non-null   float64\n",
            " 50  st_distlim       7668 non-null   int64  \n",
            " 51  st_teff          7507 non-null   float64\n",
            " 52  st_tefferr1      7195 non-null   float64\n",
            " 53  st_tefferr2      7195 non-null   float64\n",
            " 54  st_tefflim       7668 non-null   int64  \n",
            " 55  st_logg          6812 non-null   float64\n",
            " 56  st_loggerr1      5411 non-null   float64\n",
            " 57  st_loggerr2      5411 non-null   float64\n",
            " 58  st_logglim       7668 non-null   int64  \n",
            " 59  st_rad           7163 non-null   float64\n",
            " 60  st_raderr1       5718 non-null   float64\n",
            " 61  st_raderr2       5718 non-null   float64\n",
            " 62  st_radlim        7668 non-null   int64  \n",
            " 63  toi_created      7668 non-null   object \n",
            " 64  rowupdate        7668 non-null   object \n",
            "dtypes: float64(49), int64(11), object(5)\n",
            "memory usage: 3.8+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(main_data.shape)\n",
        "print(main_data.isna().sum().sum())\n",
        "print(main_data.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "main_data = main_data.drop(columns=['rastr','decstr','toi','tid','toi_created','rowupdate'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oblKp7hEA5WQ"
      },
      "outputs": [],
      "source": [
        "def handling_missing(df):\n",
        "     df = df.dropna(axis=1, thresh=len(df)*0.4)\n",
        "     df = df.drop(columns=(df == 0).mean()[ (df == 0).mean() >= 0.9 ].index)\n",
        "     df = df.dropna()\n",
        "     return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zf3bxubGA5WQ"
      },
      "outputs": [],
      "source": [
        "def drop_sym_columns(df, threshold=0.95):\n",
        "    numerical_df = df.select_dtypes(['int','float'])\n",
        "    numerical_columns = numerical_df.columns\n",
        "    corr_matrix = numerical_df.corr()\n",
        "    drop_columns = set()\n",
        "    corr_matrix = abs(corr_matrix)\n",
        "    for i in range(len(corr_matrix.index)):\n",
        "        for j in range(i,len(corr_matrix.index)):\n",
        "            if corr_matrix.iloc[i,j] > threshold and corr_matrix.index[i] != corr_matrix.columns[j]:\n",
        "                drop_columns.add(numerical_columns[j])\n",
        "    print(list(drop_columns))\n",
        "    print(numerical_df.corr().to_string())\n",
        "    return df.drop(columns = list(drop_columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9j49O-BpA5WR"
      },
      "outputs": [],
      "source": [
        "def splitting_data(df,test_size):\n",
        "    X = df.drop(columns=[\"tfopwg_disp\"])\n",
        "    Y = df['tfopwg_disp']\n",
        "\n",
        "    x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size = test_size, random_state = 42)\n",
        "    return x_train,x_test,y_train,y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3u0jNsDyAa7Z"
      },
      "outputs": [],
      "source": [
        "def encoding_cate_columns2(y_train, y_test):\n",
        "    LE = LabelEncoder()\n",
        "    y_train_enc = LE.fit_transform(y_train)\n",
        "    y_test_enc = LE.transform(y_test)\n",
        "    decoded_labels = LE.inverse_transform(y_train_enc)\n",
        "    print(\"Mapping:\", dict(zip(LE.classes_, LE.transform(LE.classes_))))\n",
        "    return y_train_enc, y_test_enc\n",
        "\n",
        "\n",
        "def encode_dataframe_categoricals(df):\n",
        "    df = df.copy()\n",
        "    cat_cols = df.select_dtypes(include='object').columns\n",
        "    for col in cat_cols:\n",
        "        df.loc[:, col] = df[col].astype('category').cat.codes\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iZ-q5xitA5WR"
      },
      "outputs": [],
      "source": [
        "def scaling_columns(x_train,x_test):\n",
        "    x_train_min = np.min(x_train,axis=0)\n",
        "    x_train_max = np.max(x_train,axis = 0)\n",
        "    x_train[:] = (x_train-x_train_min)/(x_train_max-x_train_min)\n",
        "    x_test[:] = (x_test-x_train_min)/(x_train_max-x_train_min)\n",
        "    return x_train, x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gWg01OPmA5WR"
      },
      "outputs": [],
      "source": [
        "def feature_selection(x_train,y_train,x_test):\n",
        "\n",
        "    from sklearn.feature_selection import RFECV\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    est = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "    rfecv = RFECV(\n",
        "        estimator=est,\n",
        "        step=1,               # remove one feature at a time\n",
        "        cv=5,                 # cross-validation folds\n",
        "        scoring=\"f1_macro\",    # metric\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rfecv.fit(x_train, y_train)\n",
        "\n",
        "    selected_cols = x_train.columns[rfecv.support_]\n",
        "    print(\"Optimal number of features:\", len(selected_cols))\n",
        "    print(\"Selected features:\", selected_cols.tolist())\n",
        "\n",
        "    x_train = x_train[selected_cols]\n",
        "    x_test = x_test[selected_cols]\n",
        "    return x_train,x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calling Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eQOPqW9A5WR",
        "outputId": "3640b512-c0b9-42ff-f295-390a95fda148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['st_loggerr2', 'st_raderr2', 'st_tefferr2', 'st_tmagerr2', 'pl_tranmiderr2', 'st_disterr2', 'pl_trandurherr2', 'pl_trandeperr2', 'st_pmraerr2', 'pl_orbpererr2', 'st_pmdecerr2', 'pl_radeerr2']\n",
            "                       ra       dec   st_pmra  st_pmraerr1  st_pmraerr2  st_pmdec  st_pmdecerr1  st_pmdecerr2  pl_tranmid  pl_tranmiderr1  pl_tranmiderr2  pl_orbper  pl_orbpererr1  pl_orbpererr2  pl_trandurh  pl_trandurherr1  pl_trandurherr2  pl_trandep  pl_trandeperr1  pl_trandeperr2   pl_rade  pl_radeerr1  pl_radeerr2  pl_insol    pl_eqt   st_tmag  st_tmagerr1  st_tmagerr2   st_dist  st_disterr1  st_disterr2   st_teff  st_tefferr1  st_tefferr2   st_logg  st_loggerr1  st_loggerr2    st_rad  st_raderr1  st_raderr2\n",
            "ra               1.000000  0.206753 -0.014470    -0.083651     0.083651  0.032255     -0.051618      0.051618    0.197575        0.017801       -0.017801  -0.014639      -0.014814       0.014814     0.010715         0.023134        -0.023134    0.023249        0.035841       -0.035841  0.046876     0.001554    -0.001554  0.010777  0.026347  0.031606     0.054363    -0.054363  0.039730    -0.021591     0.021591  0.027610     0.033593    -0.033593 -0.015410    -0.055993     0.055993  0.014282   -0.033408    0.033408\n",
            "dec              0.206753  1.000000  0.021558    -0.026915     0.026915  0.024711     -0.038206      0.038206    0.286409       -0.028061        0.028061  -0.029403      -0.027822       0.027822    -0.012978         0.042771        -0.042771   -0.009359        0.057142       -0.057142 -0.031501    -0.040559     0.040559 -0.015710 -0.026013  0.005509     0.141730    -0.141730 -0.036313    -0.036088     0.036088 -0.032278    -0.080477     0.080477  0.022821    -0.232023     0.232023 -0.020275   -0.032903    0.032903\n",
            "st_pmra         -0.014470  0.021558  1.000000    -0.006583     0.006583 -0.046153     -0.000703      0.000703   -0.000960        0.015976       -0.015976   0.014359      -0.000681       0.000681    -0.004748         0.012158        -0.012158   -0.021372        0.015307       -0.015307 -0.011297     0.012005    -0.012005 -0.006401 -0.011722  0.009539     0.002579    -0.002579 -0.015259    -0.007620     0.007620 -0.027391     0.015047    -0.015047  0.017757    -0.001424     0.001424 -0.019938   -0.006247    0.006247\n",
            "st_pmraerr1     -0.083651 -0.026915 -0.006583     1.000000    -1.000000 -0.043319      0.877536     -0.877536   -0.026398        0.001331       -0.001331   0.005114       0.030855      -0.030855    -0.065314        -0.019626         0.019626    0.067743        0.096230       -0.096230 -0.014937     0.048220    -0.048220  0.028139 -0.005819 -0.103160    -0.007256     0.007256 -0.130905     0.101183    -0.101183 -0.050559     0.000007    -0.000007  0.033102     0.048825    -0.048825 -0.005483    0.087735   -0.087735\n",
            "st_pmraerr2      0.083651  0.026915  0.006583    -1.000000     1.000000  0.043319     -0.877536      0.877536    0.026398       -0.001331        0.001331  -0.005114      -0.030855       0.030855     0.065314         0.019626        -0.019626   -0.067743       -0.096230        0.096230  0.014937    -0.048220     0.048220 -0.028139  0.005819  0.103160     0.007256    -0.007256  0.130905    -0.101183     0.101183  0.050559    -0.000007     0.000007 -0.033102    -0.048825     0.048825  0.005483   -0.087735    0.087735\n",
            "st_pmdec         0.032255  0.024711 -0.046153    -0.043319     0.043319  1.000000     -0.023050      0.023050    0.042992       -0.007054        0.007054  -0.022819      -0.029880       0.029880     0.062928         0.006923        -0.006923    0.007687       -0.017521        0.017521  0.086646     0.010373    -0.010373  0.024206  0.070894  0.046201     0.013063    -0.013063  0.113231     0.040428    -0.040428  0.137253     0.007687    -0.007687 -0.128292    -0.011329     0.011329  0.113705    0.069374   -0.069374\n",
            "st_pmdecerr1    -0.051618 -0.038206 -0.000703     0.877536    -0.877536 -0.023050      1.000000     -1.000000   -0.055694        0.002619       -0.002619   0.004615       0.033338      -0.033338    -0.062642        -0.018627         0.018627    0.053229        0.081815       -0.081815 -0.025374     0.049577    -0.049577  0.031011  0.003845 -0.108914    -0.008228     0.008228 -0.128343     0.113737    -0.113737 -0.047402     0.001510    -0.001510  0.025450     0.045413    -0.045413  0.001258    0.095395   -0.095395\n",
            "st_pmdecerr2     0.051618  0.038206  0.000703    -0.877536     0.877536  0.023050     -1.000000      1.000000    0.055694       -0.002619        0.002619  -0.004615      -0.033338       0.033338     0.062642         0.018627        -0.018627   -0.053229       -0.081815        0.081815  0.025374    -0.049577     0.049577 -0.031011 -0.003845  0.108914     0.008228    -0.008228  0.128343    -0.113737     0.113737  0.047402    -0.001510     0.001510 -0.025450    -0.045413     0.045413 -0.001258   -0.095395    0.095395\n",
            "pl_tranmid       0.197575  0.286409 -0.000960    -0.026398     0.026398  0.042992     -0.055694      0.055694    1.000000        0.013313       -0.013313  -0.126828      -0.164370       0.164370    -0.034742         0.081184        -0.081184    0.036049        0.132037       -0.132037  0.124642    -0.078182     0.078182 -0.015794  0.066081  0.048470     0.062737    -0.062737  0.135431     0.057102    -0.057102  0.111367    -0.020085     0.020085 -0.114705    -0.169990     0.169990  0.082683    0.007446   -0.007446\n",
            "pl_tranmiderr1   0.017801 -0.028061  0.015976     0.001331    -0.001331 -0.007054      0.002619     -0.002619    0.013313        1.000000       -1.000000   0.004933       0.143691      -0.143691     0.018340         0.154481        -0.154481   -0.033059        0.011340       -0.011340 -0.045223     0.001132    -0.001132 -0.006529 -0.024340 -0.018681    -0.003380     0.003380 -0.014545    -0.005522     0.005522 -0.002970    -0.004909     0.004909  0.001986    -0.009086     0.009086 -0.002983    0.002196   -0.002196\n",
            "pl_tranmiderr2  -0.017801  0.028061 -0.015976    -0.001331     0.001331  0.007054     -0.002619      0.002619   -0.013313       -1.000000        1.000000  -0.004933      -0.143691       0.143691    -0.018340        -0.154481         0.154481    0.033059       -0.011340        0.011340  0.045223    -0.001132     0.001132  0.006529  0.024340  0.018681     0.003380    -0.003380  0.014545     0.005522    -0.005522  0.002970     0.004909    -0.004909 -0.001986     0.009086    -0.009086  0.002983   -0.002196    0.002196\n",
            "pl_orbper       -0.014639 -0.029403  0.014359     0.005114    -0.005114 -0.022819      0.004615     -0.004615   -0.126828        0.004933       -0.004933   1.000000       0.328322      -0.328322     0.243817         0.079729        -0.079729   -0.024537        0.004314       -0.004314 -0.073011    -0.018209     0.018209 -0.038082 -0.211722 -0.117274    -0.031365     0.031365 -0.109877    -0.047779     0.047779 -0.036617    -0.014101     0.014101  0.052083    -0.016498     0.016498 -0.053745   -0.036765    0.036765\n",
            "pl_orbpererr1   -0.014814 -0.027822 -0.000681     0.030855    -0.030855 -0.029880      0.033338     -0.033338   -0.164370        0.143691       -0.143691   0.328322       1.000000      -1.000000     0.327187         0.206027        -0.206027   -0.035190       -0.006865        0.006865 -0.086041     0.036469    -0.036469 -0.033272 -0.169396 -0.097795    -0.031922     0.031922 -0.085992    -0.037974     0.037974 -0.013355    -0.005580     0.005580 -0.002373    -0.005972     0.005972 -0.002112    0.019778   -0.019778\n",
            "pl_orbpererr2    0.014814  0.027822  0.000681    -0.030855     0.030855  0.029880     -0.033338      0.033338    0.164370       -0.143691        0.143691  -0.328322      -1.000000       1.000000    -0.327187        -0.206027         0.206027    0.035190        0.006865       -0.006865  0.086041    -0.036469     0.036469  0.033272  0.169396  0.097795     0.031922    -0.031922  0.085992     0.037974    -0.037974  0.013355     0.005580    -0.005580  0.002373     0.005972    -0.005972  0.002112   -0.019778    0.019778\n",
            "pl_trandurh      0.010715 -0.012978 -0.004748    -0.065314     0.065314  0.062928     -0.062642      0.062642   -0.034742        0.018340       -0.018340   0.243817       0.327187      -0.327187     1.000000         0.292620        -0.292620   -0.059127       -0.113627        0.113627  0.111214    -0.087080     0.087080 -0.050833 -0.058663 -0.152847     0.013625    -0.013625  0.126161     0.034121    -0.034121  0.208214    -0.021870     0.021870 -0.278197     0.028818    -0.028818  0.255798    0.132541   -0.132541\n",
            "pl_trandurherr1  0.023134  0.042771  0.012158    -0.019626     0.019626  0.006923     -0.018627      0.018627    0.081184        0.154481       -0.154481   0.079729       0.206027      -0.206027     0.292620         1.000000        -1.000000   -0.262852        0.051755       -0.051755 -0.278897    -0.018426     0.018426 -0.019208 -0.032763 -0.127929     0.042917    -0.042917  0.004839     0.023681    -0.023681  0.055041    -0.044760     0.044760 -0.086932    -0.081599     0.081599  0.089291    0.058753   -0.058753\n",
            "pl_trandurherr2 -0.023134 -0.042771 -0.012158     0.019626    -0.019626 -0.006923      0.018627     -0.018627   -0.081184       -0.154481        0.154481  -0.079729      -0.206027       0.206027    -0.292620        -1.000000         1.000000    0.262852       -0.051755        0.051755  0.278897     0.018426    -0.018426  0.019208  0.032763  0.127929    -0.042917     0.042917 -0.004839    -0.023681     0.023681 -0.055041     0.044760    -0.044760  0.086932     0.081599    -0.081599 -0.089291   -0.058753    0.058753\n",
            "pl_trandep       0.023249 -0.009359 -0.021372     0.067743    -0.067743  0.007687      0.053229     -0.053229    0.036049       -0.033059        0.033059  -0.024537      -0.035190       0.035190    -0.059127        -0.262852         0.262852    1.000000        0.252750       -0.252750  0.383032     0.179205    -0.179205 -0.070212 -0.148847  0.430453     0.019455    -0.019455  0.011485    -0.017891     0.017891 -0.218915     0.000108    -0.000108  0.224378    -0.007837     0.007837 -0.211643   -0.131120    0.131120\n",
            "pl_trandeperr1   0.035841  0.057142  0.015307     0.096230    -0.096230 -0.017521      0.081815     -0.081815    0.132037        0.011340       -0.011340   0.004314      -0.006865       0.006865    -0.113627         0.051755        -0.051755    0.252750        1.000000       -1.000000  0.195388     0.243621    -0.243621 -0.000400 -0.039711  0.191638     0.006067    -0.006067 -0.035824    -0.007346     0.007346 -0.140000     0.010329    -0.010329  0.120070    -0.040359     0.040359 -0.106671   -0.071029    0.071029\n",
            "pl_trandeperr2  -0.035841 -0.057142 -0.015307    -0.096230     0.096230  0.017521     -0.081815      0.081815   -0.132037       -0.011340        0.011340  -0.004314       0.006865      -0.006865     0.113627        -0.051755         0.051755   -0.252750       -1.000000        1.000000 -0.195388    -0.243621     0.243621  0.000400  0.039711 -0.191638    -0.006067     0.006067  0.035824     0.007346    -0.007346  0.140000    -0.010329     0.010329 -0.120070     0.040359    -0.040359  0.106671    0.071029   -0.071029\n",
            "pl_rade          0.046876 -0.031501 -0.011297    -0.014937     0.014937  0.086646     -0.025374      0.025374    0.124642       -0.045223        0.045223  -0.073011      -0.086041       0.086041     0.111214        -0.278897         0.278897    0.383032        0.195388       -0.195388  1.000000     0.344856    -0.344856  0.089472  0.310554  0.281366     0.123001    -0.123001  0.561460     0.283647    -0.283647  0.362448     0.037953    -0.037953 -0.459229     0.081828    -0.081828  0.477339    0.295204   -0.295204\n",
            "pl_radeerr1      0.001554 -0.040559  0.012005     0.048220    -0.048220  0.010373      0.049577     -0.049577   -0.078182        0.001132       -0.001132  -0.018209       0.036469      -0.036469    -0.087080        -0.018426         0.018426    0.179205        0.243621       -0.243621  0.344856     1.000000    -1.000000  0.114857  0.152017  0.047224     0.032836    -0.032836  0.100594     0.104821    -0.104821  0.068404     0.043189    -0.043189 -0.098773     0.066468    -0.066468  0.137925    0.162919   -0.162919\n",
            "pl_radeerr2     -0.001554  0.040559 -0.012005    -0.048220     0.048220 -0.010373     -0.049577      0.049577    0.078182       -0.001132        0.001132   0.018209      -0.036469       0.036469     0.087080         0.018426        -0.018426   -0.179205       -0.243621        0.243621 -0.344856    -1.000000     1.000000 -0.114857 -0.152017 -0.047224    -0.032836     0.032836 -0.100594    -0.104821     0.104821 -0.068404    -0.043189     0.043189  0.098773    -0.066468     0.066468 -0.137925   -0.162919    0.162919\n",
            "pl_insol         0.010777 -0.015710 -0.006401     0.028139    -0.028139  0.024206      0.031011     -0.031011   -0.015794       -0.006529        0.006529  -0.038082      -0.033272       0.033272    -0.050833        -0.019208         0.019208   -0.070212       -0.000400        0.000400  0.089472     0.114857    -0.114857  1.000000  0.630294 -0.132398     0.037738    -0.037738  0.098403     0.080709    -0.080709  0.318423     0.031322    -0.031322 -0.164627     0.015665    -0.015665  0.258953    0.122076   -0.122076\n",
            "pl_eqt           0.026347 -0.026013 -0.011722    -0.005819     0.005819  0.070894      0.003845     -0.003845    0.066081       -0.024340        0.024340  -0.211722      -0.169396       0.169396    -0.058663        -0.032763         0.032763   -0.148847       -0.039711        0.039711  0.310554     0.152017    -0.152017  0.630294  1.000000 -0.125230     0.125365    -0.125365  0.403416     0.223390    -0.223390  0.586649     0.061350    -0.061350 -0.489186     0.058656    -0.058656  0.568795    0.298233   -0.298233\n",
            "st_tmag          0.031606  0.005509  0.009539    -0.103160     0.103160  0.046201     -0.108914      0.108914    0.048470       -0.018681        0.018681  -0.117274      -0.097795       0.097795    -0.152847        -0.127929         0.127929    0.430453        0.191638       -0.191638  0.281366     0.047224    -0.047224 -0.132398 -0.125230  1.000000     0.121749    -0.121749  0.459585     0.164394    -0.164394 -0.240280     0.030491    -0.030491  0.157275    -0.061605     0.061605 -0.191096   -0.091471    0.091471\n",
            "st_tmagerr1      0.054363  0.141730  0.002579    -0.007256     0.007256  0.013063     -0.008228      0.008228    0.062737       -0.003380        0.003380  -0.031365      -0.031922       0.031922     0.013625         0.042917        -0.042917    0.019455        0.006067       -0.006067  0.123001     0.032836    -0.032836  0.037738  0.125365  0.121749     1.000000    -1.000000  0.247930     0.313424    -0.313424  0.164606     0.046766    -0.046766 -0.132525    -0.013912     0.013912  0.168841    0.212194   -0.212194\n",
            "st_tmagerr2     -0.054363 -0.141730 -0.002579     0.007256    -0.007256 -0.013063      0.008228     -0.008228   -0.062737        0.003380       -0.003380   0.031365       0.031922      -0.031922    -0.013625        -0.042917         0.042917   -0.019455       -0.006067        0.006067 -0.123001    -0.032836     0.032836 -0.037738 -0.125365 -0.121749    -1.000000     1.000000 -0.247930    -0.313424     0.313424 -0.164606    -0.046766     0.046766  0.132525     0.013912    -0.013912 -0.168841   -0.212194    0.212194\n",
            "st_dist          0.039730 -0.036313 -0.015259    -0.130905     0.130905  0.113231     -0.128343      0.128343    0.135431       -0.014545        0.014545  -0.109877      -0.085992       0.085992     0.126161         0.004839        -0.004839    0.011485       -0.035824        0.035824  0.561460     0.100594    -0.100594  0.098403  0.403416  0.459585     0.247930    -0.247930  1.000000     0.600861    -0.600861  0.535323     0.039516    -0.039516 -0.591455     0.004264    -0.004264  0.622207    0.437369   -0.437369\n",
            "st_disterr1     -0.021591 -0.036088 -0.007620     0.101183    -0.101183  0.040428      0.113737     -0.113737    0.057102       -0.005522        0.005522  -0.047779      -0.037974       0.037974     0.034121         0.023681        -0.023681   -0.017891       -0.007346        0.007346  0.283647     0.104821    -0.104821  0.080709  0.223390  0.164394     0.313424    -0.313424  0.600861     1.000000    -1.000000  0.321581     0.016534    -0.016534 -0.305963     0.049895    -0.049895  0.380505    0.614693   -0.614693\n",
            "st_disterr2      0.021591  0.036088  0.007620    -0.101183     0.101183 -0.040428     -0.113737      0.113737   -0.057102        0.005522       -0.005522   0.047779       0.037974      -0.037974    -0.034121        -0.023681         0.023681    0.017891        0.007346       -0.007346 -0.283647    -0.104821     0.104821 -0.080709 -0.223390 -0.164394    -0.313424     0.313424 -0.600861    -1.000000     1.000000 -0.321581    -0.016534     0.016534  0.305963    -0.049895     0.049895 -0.380505   -0.614693    0.614693\n",
            "st_teff          0.027610 -0.032278 -0.027391    -0.050559     0.050559  0.137253     -0.047402      0.047402    0.111367       -0.002970        0.002970  -0.036617      -0.013355       0.013355     0.208214         0.055041        -0.055041   -0.218915       -0.140000        0.140000  0.362448     0.068404    -0.068404  0.318423  0.586649 -0.240280     0.164606    -0.164606  0.535323     0.321581    -0.321581  1.000000     0.096430    -0.096430 -0.565900     0.032320    -0.032320  0.672561    0.357727   -0.357727\n",
            "st_tefferr1      0.033593 -0.080477  0.015047     0.000007    -0.000007  0.007687      0.001510     -0.001510   -0.020085       -0.004909        0.004909  -0.014101      -0.005580       0.005580    -0.021870        -0.044760         0.044760    0.000108        0.010329       -0.010329  0.037953     0.043189    -0.043189  0.031322  0.061350  0.030491     0.046766    -0.046766  0.039516     0.016534    -0.016534  0.096430     1.000000    -1.000000  0.010680     0.390619    -0.390619  0.019736    0.025815   -0.025815\n",
            "st_tefferr2     -0.033593  0.080477 -0.015047    -0.000007     0.000007 -0.007687     -0.001510      0.001510    0.020085        0.004909       -0.004909   0.014101       0.005580      -0.005580     0.021870         0.044760        -0.044760   -0.000108       -0.010329        0.010329 -0.037953    -0.043189     0.043189 -0.031322 -0.061350 -0.030491    -0.046766     0.046766 -0.039516    -0.016534     0.016534 -0.096430    -1.000000     1.000000 -0.010680    -0.390619     0.390619 -0.019736   -0.025815    0.025815\n",
            "st_logg         -0.015410  0.022821  0.017757     0.033102    -0.033102 -0.128292      0.025450     -0.025450   -0.114705        0.001986       -0.001986   0.052083      -0.002373       0.002373    -0.278197        -0.086932         0.086932    0.224378        0.120070       -0.120070 -0.459229    -0.098773     0.098773 -0.164627 -0.489186  0.157275    -0.132525     0.132525 -0.591455    -0.305963     0.305963 -0.565900     0.010680    -0.010680  1.000000     0.005572    -0.005572 -0.905082   -0.571211    0.571211\n",
            "st_loggerr1     -0.055993 -0.232023 -0.001424     0.048825    -0.048825 -0.011329      0.045413     -0.045413   -0.169990       -0.009086        0.009086  -0.016498      -0.005972       0.005972     0.028818        -0.081599         0.081599   -0.007837       -0.040359        0.040359  0.081828     0.066468    -0.066468  0.015665  0.058656 -0.061605    -0.013912     0.013912  0.004264     0.049895    -0.049895  0.032320     0.390619    -0.390619  0.005572     1.000000    -1.000000  0.078944    0.140301   -0.140301\n",
            "st_loggerr2      0.055993  0.232023  0.001424    -0.048825     0.048825  0.011329     -0.045413      0.045413    0.169990        0.009086       -0.009086   0.016498       0.005972      -0.005972    -0.028818         0.081599        -0.081599    0.007837        0.040359       -0.040359 -0.081828    -0.066468     0.066468 -0.015665 -0.058656  0.061605     0.013912    -0.013912 -0.004264    -0.049895     0.049895 -0.032320    -0.390619     0.390619 -0.005572    -1.000000     1.000000 -0.078944   -0.140301    0.140301\n",
            "st_rad           0.014282 -0.020275 -0.019938    -0.005483     0.005483  0.113705      0.001258     -0.001258    0.082683       -0.002983        0.002983  -0.053745      -0.002112       0.002112     0.255798         0.089291        -0.089291   -0.211643       -0.106671        0.106671  0.477339     0.137925    -0.137925  0.258953  0.568795 -0.191096     0.168841    -0.168841  0.622207     0.380505    -0.380505  0.672561     0.019736    -0.019736 -0.905082     0.078944    -0.078944  1.000000    0.641025   -0.641025\n",
            "st_raderr1      -0.033408 -0.032903 -0.006247     0.087735    -0.087735  0.069374      0.095395     -0.095395    0.007446        0.002196       -0.002196  -0.036765       0.019778      -0.019778     0.132541         0.058753        -0.058753   -0.131120       -0.071029        0.071029  0.295204     0.162919    -0.162919  0.122076  0.298233 -0.091471     0.212194    -0.212194  0.437369     0.614693    -0.614693  0.357727     0.025815    -0.025815 -0.571211     0.140301    -0.140301  0.641025    1.000000   -1.000000\n",
            "st_raderr2       0.033408  0.032903  0.006247    -0.087735     0.087735 -0.069374     -0.095395      0.095395   -0.007446       -0.002196        0.002196   0.036765      -0.019778       0.019778    -0.132541        -0.058753         0.058753    0.131120        0.071029       -0.071029 -0.295204    -0.162919     0.162919 -0.122076 -0.298233  0.091471    -0.212194     0.212194 -0.437369    -0.614693     0.614693 -0.357727    -0.025815     0.025815  0.571211    -0.140301     0.140301 -0.641025   -1.000000    1.000000\n",
            "Mapping: {'APC': np.int64(0), 'CP': np.int64(1), 'FA': np.int64(2), 'FP': np.int64(3), 'KP': np.int64(4), 'PC': np.int64(5)}\n",
            "Optimal number of features: 18\n",
            "Selected features: ['dec', 'st_pmdec', 'pl_tranmid', 'pl_tranmiderr1', 'pl_orbper', 'pl_orbpererr1', 'pl_trandurh', 'pl_trandurherr1', 'pl_trandep', 'pl_trandeperr1', 'pl_rade', 'pl_radeerr1', 'pl_insol', 'pl_eqt', 'st_tmag', 'st_dist', 'st_disterr1', 'st_tefferr1']\n"
          ]
        }
      ],
      "source": [
        "main_data = handling_missing(main_data)\n",
        "main_data = drop_sym_columns(main_data, 0.95)\n",
        "x_train,x_test,y_train,y_test = splitting_data(main_data,0.2)\n",
        "y_train,y_test = encoding_cate_columns2(y_train,y_test)\n",
        "x_train,x_test = feature_selection(x_train,y_train,x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick check on changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEC0xZbxA5WS",
        "outputId": "f4f2b370-cd0e-42f8-ed35-0bed512f7e5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5124, 29)\n",
            "0\n",
            "(4099, 18)\n"
          ]
        }
      ],
      "source": [
        "print(main_data.shape)\n",
        "print(main_data.isna().sum().sum())\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Features: \n",
            " 18 Features: ['dec', 'st_pmdec', 'pl_tranmid', 'pl_tranmiderr1', 'pl_orbper', 'pl_orbpererr1', 'pl_trandurh', 'pl_trandurherr1', 'pl_trandep', 'pl_trandeperr1', 'pl_rade', 'pl_radeerr1', 'pl_insol', 'pl_eqt', 'st_tmag', 'st_dist', 'st_disterr1', 'st_tefferr1']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best Features: \\n{len(x_train.columns)} Features: {list(x_train.columns)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlZNc4RHA5WS",
        "outputId": "eda91b11-d5d9-4273-98c8-cb5114d90aa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression\n",
            "Accuracy: 0.5990243902439024\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        53\n",
            "           1       0.00      0.00      0.00       123\n",
            "           2       0.00      0.00      0.00        15\n",
            "           3       0.79      0.09      0.16       165\n",
            "           4       0.00      0.00      0.00        67\n",
            "           5       0.60      1.00      0.75       602\n",
            "\n",
            "    accuracy                           0.60      1025\n",
            "   macro avg       0.23      0.18      0.15      1025\n",
            "weighted avg       0.48      0.60      0.46      1025\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\m1-ra\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\m1-ra\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\m1-ra\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\m1-ra\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "lr = LogisticRegression(max_iter=500)\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred = lr.predict(x_test)\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "r5lf72QAgFHX",
        "outputId": "a17cff7e-be95-45c7-9fa0-7885b98f2e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best k: 43\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best k: 43 with Accuracy: 0.6042901813633521\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "neighbors = range(1, 50)\n",
        "scores = []\n",
        "\n",
        "for k in neighbors:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    cv_score = cross_val_score(knn, x_train, y_train, cv=5, scoring=\"accuracy\")\n",
        "    scores.append(cv_score.mean())\n",
        "\n",
        "best_k = neighbors[np.argmax(scores)]\n",
        "print(\"Best k:\", best_k)\n",
        "\n",
        "plt.plot(neighbors, scores, marker='o')\n",
        "plt.xlabel(\"n_neighbors (k)\")\n",
        "plt.ylabel(\"Cross-validated Accuracy\")\n",
        "plt.title(\"Choosing best k for KNN\")\n",
        "plt.show()\n",
        "print(\"Best k:\", best_k, \"with Accuracy:\", max(scores))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHev5-KOgdhy",
        "outputId": "25796647-2436-4b73-8e08-29397ee26567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN with k=43\n",
            "Accuracy: 0.6126829268292683\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        53\n",
            "           1       0.33      0.01      0.02       123\n",
            "           2       0.00      0.00      0.00        15\n",
            "           3       0.57      0.27      0.37       165\n",
            "           4       0.00      0.00      0.00        67\n",
            "           5       0.62      0.97      0.75       602\n",
            "\n",
            "    accuracy                           0.61      1025\n",
            "   macro avg       0.25      0.21      0.19      1025\n",
            "weighted avg       0.49      0.61      0.50      1025\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\m1-ra\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\m1-ra\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\m1-ra\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=43)\n",
        "knn.fit(x_train, y_train)\n",
        "y_pred = knn.predict(x_test)\n",
        "\n",
        "print(\"KNN with k=43\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCe_hdy_jmaz",
        "outputId": "0322b642-404e-4e42-cbd2-8fa87c48bf30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree (ID3)\n",
            "Accuracy: 0.5346341463414634\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.19      0.17        53\n",
            "           1       0.33      0.29      0.31       123\n",
            "           2       0.00      0.00      0.00        15\n",
            "           3       0.44      0.42      0.43       165\n",
            "           4       0.26      0.33      0.29        67\n",
            "           5       0.68      0.68      0.68       602\n",
            "\n",
            "    accuracy                           0.53      1025\n",
            "   macro avg       0.31      0.32      0.31      1025\n",
            "weighted avg       0.54      0.53      0.53      1025\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
        "dt.fit(x_train, y_train)\n",
        "y_pred = dt.predict(x_test)\n",
        "\n",
        "print(\"Decision Tree (ID3)\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQEoujJYjtGY",
        "outputId": "2289b7d9-5e44-4ed2-e441-7c919b00dd01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM\n",
            "Accuracy: 0.5873170731707317\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        53\n",
            "           1       0.00      0.00      0.00       123\n",
            "           2       0.00      0.00      0.00        15\n",
            "           3       0.00      0.00      0.00       165\n",
            "           4       0.00      0.00      0.00        67\n",
            "           5       0.59      1.00      0.74       602\n",
            "\n",
            "    accuracy                           0.59      1025\n",
            "   macro avg       0.10      0.17      0.12      1025\n",
            "weighted avg       0.34      0.59      0.43      1025\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\m1-ra\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\m1-ra\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\m1-ra\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(x_train, y_train)\n",
        "y_pred = svm.predict(x_test)\n",
        "\n",
        "print(\"SVM\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVIk7TH-jyRs",
        "outputId": "9a7cfab0-1ea9-4eaa-e99d-1b98ae5d289c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest\n",
            "Accuracy: 0.6839024390243903\n",
            "Recall (macro): 0.33872242117536794\n",
            "Precision (macro): 0.497393047006449\n",
            "F1 Score (macro): 0.3742783620571008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\m1-ra\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(x_train, y_train)\n",
        "y_pred = rf.predict(x_test)\n",
        "\n",
        "print(\"Random Forest\")\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwsyZu40kBzq",
        "outputId": "fad53443-917f-4bea-ec6d-0cfa3f0d3d8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting\n",
            "Accuracy: 0.6809756097560976\n",
            "Recall (macro): 0.3826475077773275\n",
            "Precision (macro): 0.5491432439057424\n",
            "F1 Score (macro): 0.42911410093570107\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score,recall_score\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb.fit(x_train, y_train)\n",
        "y_pred = gb.predict(x_test)\n",
        "\n",
        "print(\"Gradient Boosting\")\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### The best model is the Gradient Boosting Classifier based on the evaluation metrics above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dEYTjm0kkHP1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model saved as model.joblib\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(gb, \"model.joblib\")\n",
        "print(\"✅ Model saved as model.joblib\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
